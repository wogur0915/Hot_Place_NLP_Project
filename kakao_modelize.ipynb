{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import re\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>ëª…ë¶ˆí—ˆì „</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>ì´ê±°ìŠ¨ í•œêµ­ì˜ ê¹Œë¥´ë³´ë‚˜ë¼,,,ğŸ¤ ë“¤ê¹¨ì¹¼êµ­ìˆ˜ ê³ ì†Œí•˜ë‹ˆ ë„˜ ë§›ë‚˜ìœ  ì–¼í°í•´ë¬¼ì¹¼êµ­ìˆ˜ëŠ” í•´ë¬¼...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>ë“¤ê¹¨ê°€ ì°í•˜ê³  ê³ ì†Œí•´ìš”. ìŒì‹ë§›ì´ ê¹”ë”í•´ìš”. ì–´ë¥´ì‹  ëª¨ì‹œê³  ì²­ì£¼ ì˜¨ë‹¤ë©´ ì‹ì‚¬í•˜ê¸° ê´œ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>ì²­ì£¼ ì‚¬ëŒë“¤ ì ì‹¬ì—” ì—¬ê¸°ë§Œ ì˜¤ë‚˜ë´ìš”. ì£¼ë§ ì ì‹¬ì‹œê°„ì— ì™”ëŠ”ë° ì†ë‹˜ 100ëª…ì€ ì•‰ì•„ìˆ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4ëª…ì—ì„œ 3~4ì¸ ì…‹íŠ¸ì‹œí‚¤ë©´ ì§„ì§œ ë°°í„°ì§€ê²Œ ë¨¹ê³ ë‚˜ì˜¬ìˆ˜ìˆì–´ìš”!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>ë“¤ê¹¨ì¹¼êµ­ìˆ˜ ë•¡ê¸°ë©´ ì°¾ì•„ê°€ëŠ”ê³³</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>ì¼í•˜ì‹œëŠ”ë¶„ë“¤ì´ ì¹œì ˆí•˜ê³  ìŒì‹ì´ ë“¤ê¹¨ì¹¼êµ­ìˆ˜ ë§›ìˆì–´ìš”</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>ë§›ì€ì¢‹ì•„ìš”. ì£¼ë°©ì•„ì¤Œë§ˆë“¤ í™€ì´ë‚˜ ì£¼ë°©ì—ì„œ ìˆ˜ë‹¤ì¢€ ì•ˆë– ì…¨ìŒ ì¢‹ê² ì–´ìš”..ì§œì¦ë‚©ë‹ˆë‹¤. êµ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.0</td>\n",
       "      <td>ì§± ë§›ì§‘ì„ë“¤ê¹¨ì¹¼êµ­ìˆ˜, í•´ë¬¼ì¹¼êµ­ìˆ˜ ëª¨ë‘ í›Œë¥­í•¨</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.0</td>\n",
       "      <td>ê°€ì¡±ì´ë‘ ë¨¹ê¸° ì¢‹ì•„ìš” ì–‘ë„ ì™„ì „ ë§ê³  êµ­ë¬¼ì™„ì „ ì €í¬ ê°€ì¡± ìŠ¤íƒˆ~,, í•´ë¬¼íŒŒì „ë„ ë„ˆë¬´...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.0</td>\n",
       "      <td>ì›”ìš”ì¼ì—ë„ ì˜ì—…í•˜ì‹œë„¤ìš”ë§›ìˆìŠµë‹ˆë‹¤ ë°‘ë°˜ì°¬ë„ ì‹±ì‹±í•¨</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.0</td>\n",
       "      <td>ì¹¼êµ­ìˆ˜ ë§›ì€ í‰ë²”í–ˆëŠ”ë° íŒŒì „ì´ ë‘íˆ¼í•˜ê³  ë°”ì‚­í•œê²Œ ì •ë§ ë§›ìˆë„¤ìš”</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.0</td>\n",
       "      <td>ë§›ìˆì–´ìš”</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.0</td>\n",
       "      <td>ë“¤ê¹¨ ì¹¼êµ­ìˆ˜ ë§›ìˆì–´ìš”~~!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.0</td>\n",
       "      <td>ì²­ì£¼ì—ì„œ ê°€ì¡±ê³¼ ì˜¤ê¸° ì¢‹ì€ ê³³</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    score                                             review  y\n",
       "0     5.0                                               ëª…ë¶ˆí—ˆì „  1\n",
       "1     5.0  ì´ê±°ìŠ¨ í•œêµ­ì˜ ê¹Œë¥´ë³´ë‚˜ë¼,,,ğŸ¤ ë“¤ê¹¨ì¹¼êµ­ìˆ˜ ê³ ì†Œí•˜ë‹ˆ ë„˜ ë§›ë‚˜ìœ  ì–¼í°í•´ë¬¼ì¹¼êµ­ìˆ˜ëŠ” í•´ë¬¼...  1\n",
       "2     5.0  ë“¤ê¹¨ê°€ ì°í•˜ê³  ê³ ì†Œí•´ìš”. ìŒì‹ë§›ì´ ê¹”ë”í•´ìš”. ì–´ë¥´ì‹  ëª¨ì‹œê³  ì²­ì£¼ ì˜¨ë‹¤ë©´ ì‹ì‚¬í•˜ê¸° ê´œ...  1\n",
       "3     4.0  ì²­ì£¼ ì‚¬ëŒë“¤ ì ì‹¬ì—” ì—¬ê¸°ë§Œ ì˜¤ë‚˜ë´ìš”. ì£¼ë§ ì ì‹¬ì‹œê°„ì— ì™”ëŠ”ë° ì†ë‹˜ 100ëª…ì€ ì•‰ì•„ìˆ...  1\n",
       "4     5.0                                                NaN  1\n",
       "5     5.0                                                NaN  1\n",
       "6     5.0                  4ëª…ì—ì„œ 3~4ì¸ ì…‹íŠ¸ì‹œí‚¤ë©´ ì§„ì§œ ë°°í„°ì§€ê²Œ ë¨¹ê³ ë‚˜ì˜¬ìˆ˜ìˆì–´ìš”!  1\n",
       "7     5.0                                    ë“¤ê¹¨ì¹¼êµ­ìˆ˜ ë•¡ê¸°ë©´ ì°¾ì•„ê°€ëŠ”ê³³  1\n",
       "8     5.0                        ì¼í•˜ì‹œëŠ”ë¶„ë“¤ì´ ì¹œì ˆí•˜ê³  ìŒì‹ì´ ë“¤ê¹¨ì¹¼êµ­ìˆ˜ ë§›ìˆì–´ìš”  1\n",
       "9     3.0                                                NaN  0\n",
       "10    5.0  ë§›ì€ì¢‹ì•„ìš”. ì£¼ë°©ì•„ì¤Œë§ˆë“¤ í™€ì´ë‚˜ ì£¼ë°©ì—ì„œ ìˆ˜ë‹¤ì¢€ ì•ˆë– ì…¨ìŒ ì¢‹ê² ì–´ìš”..ì§œì¦ë‚©ë‹ˆë‹¤. êµ...  1\n",
       "11    5.0                           ì§± ë§›ì§‘ì„ë“¤ê¹¨ì¹¼êµ­ìˆ˜, í•´ë¬¼ì¹¼êµ­ìˆ˜ ëª¨ë‘ í›Œë¥­í•¨  1\n",
       "12    5.0                                                NaN  1\n",
       "13    5.0                                                NaN  1\n",
       "14    5.0  ê°€ì¡±ì´ë‘ ë¨¹ê¸° ì¢‹ì•„ìš” ì–‘ë„ ì™„ì „ ë§ê³  êµ­ë¬¼ì™„ì „ ì €í¬ ê°€ì¡± ìŠ¤íƒˆ~,, í•´ë¬¼íŒŒì „ë„ ë„ˆë¬´...  1\n",
       "15    4.0                         ì›”ìš”ì¼ì—ë„ ì˜ì—…í•˜ì‹œë„¤ìš”ë§›ìˆìŠµë‹ˆë‹¤ ë°‘ë°˜ì°¬ë„ ì‹±ì‹±í•¨  1\n",
       "16    4.0                 ì¹¼êµ­ìˆ˜ ë§›ì€ í‰ë²”í–ˆëŠ”ë° íŒŒì „ì´ ë‘íˆ¼í•˜ê³  ë°”ì‚­í•œê²Œ ì •ë§ ë§›ìˆë„¤ìš”  1\n",
       "17    5.0                                               ë§›ìˆì–´ìš”  1\n",
       "18    5.0                                     ë“¤ê¹¨ ì¹¼êµ­ìˆ˜ ë§›ìˆì–´ìš”~~!  1\n",
       "19    5.0                                   ì²­ì£¼ì—ì„œ ê°€ì¡±ê³¼ ì˜¤ê¸° ì¢‹ì€ ê³³  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"review_data.csv\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ í•œê¸€ë§Œ ì¶”ì¶œ\n",
    "        hangul = re.compile('[^ ã„±-ã…£ê°€-í£]+')\n",
    "        result = hangul.sub('', text)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>y</th>\n",
       "      <th>ko_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>ìƒˆìš°íŠ€ê¹€ ìš°ë™ ì²˜ìŒ ë¨¹ì–´ë´¤ëŠ”ë° ì§„ì§œ ë§›ìˆì–´ìš”ì¶©ëŒ€ ì£¼ë³€ ëˆê¹ŒìŠ¤ì§‘ ë‹¤ ë¨¹ì–´ë´¤ëŠ”ë° ì–‘ì´ë‚˜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>ì ì‹¬ì‹ì‚¬ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤ ì§„ì§œ ì¼ì‹ ëˆê¹ŒìŠ¤ì¤‘ì—ì„œëŠ”ìµœê³±ë‹ˆë‹¤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>ì¶©ë¶ëŒ€í•™êµ ë§›ì§‘ì–‘ê¼¬ì¹˜ ë§›ì§‘ì´ë‚´ìš” ëª¸ì—ì¢‹ê³  ë³´ì–‘ì‹ì´ì˜ˆìš”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>ë§›ìˆê²Œ ì˜ ë¨¹ì—ˆìŠµë‹ˆë‹¤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>ì„¸íŠ¸ ë¨¹ì—ˆëŠ”ë° í‘¸ì§í•˜ê³  ë„˜ ë§›ìˆì–´ìš” ëª…ì´ì„œ ë¨¹ì„ ì–‘</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     score  y                                            ko_text\n",
       "456    5.0  1  ìƒˆìš°íŠ€ê¹€ ìš°ë™ ì²˜ìŒ ë¨¹ì–´ë´¤ëŠ”ë° ì§„ì§œ ë§›ìˆì–´ìš”ì¶©ëŒ€ ì£¼ë³€ ëˆê¹ŒìŠ¤ì§‘ ë‹¤ ë¨¹ì–´ë´¤ëŠ”ë° ì–‘ì´ë‚˜...\n",
       "457    5.0  1                      ì ì‹¬ì‹ì‚¬ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤ ì§„ì§œ ì¼ì‹ ëˆê¹ŒìŠ¤ì¤‘ì—ì„œëŠ”ìµœê³±ë‹ˆë‹¤\n",
       "458    5.0  1                      ì¶©ë¶ëŒ€í•™êµ ë§›ì§‘ì–‘ê¼¬ì¹˜ ë§›ì§‘ì´ë‚´ìš” ëª¸ì—ì¢‹ê³  ë³´ì–‘ì‹ì´ì˜ˆìš”\n",
       "459    5.0  1                                        ë§›ìˆê²Œ ì˜ ë¨¹ì—ˆìŠµë‹ˆë‹¤\n",
       "460    5.0  1                       ì„¸íŠ¸ ë¨¹ì—ˆëŠ”ë° í‘¸ì§í•˜ê³  ë„˜ ë§›ìˆì–´ìš” ëª…ì´ì„œ ë¨¹ì„ ì–‘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"review_data.csv\")\n",
    "row = []\n",
    "for i in df['review']:\n",
    "    row.append(text_cleaning(str(i)))\n",
    "\n",
    "df['ko_text'] = row\n",
    "del df['review']\n",
    "\n",
    "# í•œ ê¸€ì ì´ìƒì˜ í…ìŠ¤íŠ¸ë¥¼ ê°€ì§€ê³  ìˆëŠ” ë°ì´í„°ë§Œ ì¶”ì¶œ\n",
    "df = df[df['ko_text'].str.len() > 0]\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### ì—¬ê¸°ì„œë¶€í„° ìì—°ì–´ì²˜ë¦¬ë¥¼ ìœ„í•œ ê³¼ì • ###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ì´ê±°ìŠ¨/Noun', 'í•œêµ­/Noun', 'ì˜/Josa', 'ê¹Œë¥´ë³´ë‚˜ë¼/Noun', 'ë“¤ê¹¨/Noun', 'ì¹¼êµ­ìˆ˜/Noun', 'ê³ ì†Œí•˜ë‹ˆ/Adjective', 'ë„˜/Verb', 'ë§›/Noun', 'ë‚˜ìœ /Noun', 'ì–¼í°í•´/Adjective', 'ë¬¼/Noun', 'ì¹¼êµ­ìˆ˜/Noun', 'ëŠ”/Josa', 'í•´ë¬¼/Noun', 'ë„/Josa', 'ë§ì´/Adverb', 'ë“¤ì–´ìˆê³ /Verb', 'ì•½ê°„/Noun', 'ì§¬ë½•/Noun', 'ëŠë‚Œ/Noun', 'í•´ë¬¼íŒŒì „/Noun', 'ë„/Josa', 'ê´œì¶˜ìŠ¤/Noun', 'ê°€ì¡±/Noun', 'ë“¤/Suffix', 'ê³¼/Josa', 'ì™¸ì‹/Noun', 'í•˜ê¸°/Verb', 'ì¢‹ìˆ©ë‹ˆ/Noun', 'ë‹¤/Josa']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "# konlpyë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ í…ìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ í˜•íƒœì†Œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "def get_pos(x):\n",
    "    tagger = Okt()\n",
    "    pos = tagger.pos(x)\n",
    "    pos = ['{}/{}'.format(word,tag) for word, tag in pos]\n",
    "    return pos\n",
    "\n",
    "# í˜•íƒœì†Œ ì¶”ì¶œ ë™ì‘ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\n",
    "result = get_pos(df['ko_text'].values[1])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# í˜•íƒœì†Œë¥¼ ë²¡í„° í˜•íƒœì˜ í•™ìŠµ ë°ì´í„°ì…‹(X ë°ì´í„°)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "index_vectorizer = CountVectorizer(tokenizer = lambda x: get_pos(x))\n",
    "X = index_vectorizer.fit_transform(df['ko_text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(358, 2871)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ëª…ë¶ˆí—ˆì „/Noun': 998, 'ì´ê±°ìŠ¨/Noun': 1988, 'í•œêµ­/Noun': 2743, 'ì˜/Josa': 1980, 'ê¹Œë¥´ë³´ë‚˜ë¼/Noun': 353, 'ë“¤ê¹¨/Noun': ..\n"
     ]
    }
   ],
   "source": [
    "print(str(index_vectorizer.vocabulary_)[:100]+\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ê±°ìŠ¨ í•œêµ­ì˜ ê¹Œë¥´ë³´ë‚˜ë¼ ë“¤ê¹¨ì¹¼êµ­ìˆ˜ ê³ ì†Œí•˜ë‹ˆ ë„˜ ë§›ë‚˜ìœ  ì–¼í°í•´ë¬¼ì¹¼êµ­ìˆ˜ëŠ” í•´ë¬¼ë„ ë§ì´ ë“¤ì–´ìˆê³  ì•½ê°„ ì§¬ë½• ëŠë‚Œ í•´ë¬¼íŒŒì „ë„ ê´œì¶˜ìŠ¤ ê°€ì¡±ë“¤ê³¼ ì™¸ì‹í•˜ê¸° ì¢‹ìˆ©ë‹ˆë‹¤\n",
      "  (0, 1988)\t1\n",
      "  (0, 2743)\t1\n",
      "  (0, 1980)\t1\n",
      "  (0, 353)\t1\n",
      "  (0, 712)\t1\n",
      "  (0, 2536)\t2\n",
      "  (0, 199)\t1\n",
      "  (0, 480)\t1\n",
      "  (0, 888)\t1\n",
      "  (0, 439)\t1\n",
      "  (0, 1755)\t1\n",
      "  (0, 1060)\t1\n",
      "  (0, 518)\t1\n",
      "  (0, 2779)\t1\n",
      "  (0, 635)\t2\n",
      "  (0, 879)\t1\n",
      "  (0, 727)\t1\n",
      "  (0, 1715)\t1\n",
      "  (0, 2391)\t1\n",
      "  (0, 517)\t1\n",
      "  (0, 2780)\t1\n",
      "  (0, 238)\t1\n",
      "  (0, 70)\t1\n",
      "  (0, 710)\t1\n",
      "  (0, 223)\t1\n",
      "  (0, 1913)\t1\n",
      "  (0, 2689)\t1\n",
      "  (0, 2269)\t1\n",
      "  (0, 532)\t1\n"
     ]
    }
   ],
   "source": [
    "print(df['ko_text'].values[1])\n",
    "print(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(358, 2871)\n",
      "  (0, 70)\t0.13752146852613395\n",
      "  (0, 199)\t0.20956126014266763\n",
      "  (0, 223)\t0.11281135076330545\n",
      "  (0, 238)\t0.23996819563825356\n",
      "  (0, 353)\t0.23996819563825356\n",
      "  (0, 439)\t0.23996819563825356\n",
      "  (0, 480)\t0.15266749563521523\n",
      "  (0, 517)\t0.12115472493502323\n",
      "  (0, 518)\t0.0560436515493697\n",
      "  (0, 532)\t0.16234915509570746\n",
      "  (0, 635)\t0.0725043121303412\n",
      "  (0, 710)\t0.06935978489428739\n",
      "  (0, 712)\t0.12115472493502323\n",
      "  (0, 727)\t0.23996819563825356\n",
      "  (0, 879)\t0.0998471525154526\n",
      "  (0, 888)\t0.039181214580866944\n",
      "  (0, 1060)\t0.20956126014266763\n",
      "  (0, 1715)\t0.23996819563825356\n",
      "  (0, 1755)\t0.23996819563825356\n",
      "  (0, 1913)\t0.23996819563825356\n",
      "  (0, 1980)\t0.0998471525154526\n",
      "  (0, 1988)\t0.23996819563825356\n",
      "  (0, 2269)\t0.23996819563825356\n",
      "  (0, 2391)\t0.20956126014266763\n",
      "  (0, 2536)\t0.2335705635057902\n",
      "  (0, 2689)\t0.14452143213060348\n",
      "  (0, 2743)\t0.23996819563825356\n",
      "  (0, 2779)\t0.18923597644129056\n",
      "  (0, 2780)\t0.18923597644129056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# TF-IDF ë°©ë²•ìœ¼ë¡œ, í˜•íƒœì†Œë¥¼ ë²¡í„° í˜•íƒœì˜ í•™ìŠµ ë°ì´í„°ì…‹(X ë°ì´í„°)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "tfidf_vectorizer = TfidfTransformer()\n",
    "X = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "print(X.shape)\n",
    "print(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(286, 2871)\n",
      "(72, 2871)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['y']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.20)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.71\n",
      "Precision: 0.708\n",
      "Recall: 1.000\n",
      "F1: 0.829\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(x_train, y_train)\n",
    "y_pred = lr.predict(x_test)\n",
    "y_pred_probability = lr.predict_proba(x_test)[:,1]\n",
    "\n",
    "print(\"accuracy: %.2f\" % accuracy_score(y_test, y_pred))\n",
    "print(\"Precision: %.3f\" % precision_score(y_test,y_pred))\n",
    "print(\"Recall: %.3f\" % recall_score(y_test, y_pred))\n",
    "print(\"F1: %.3f\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 21]\n",
      " [ 0 51]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confmat=confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "1    241\n",
       "0    117\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yê°€ 0ê³¼ 1ì„ ê°ê° ì–¼ë§ˆë‚˜ ê°€ì§€ê³  ìˆëŠ”ì§€ë¥¼ ì¶œë ¥\n",
    "df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œ í•´ê²°í•˜ê¸° (1:1 ë¹„ìœ¨ì˜ ëœë¤ ìƒ˜í”Œë§)\n",
    "positive_random_idx = df[df['y']==1].sample(50, random_state=30).index.tolist()\n",
    "negative_random_idx = df[df['y']==0].sample(50, random_state=30).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
